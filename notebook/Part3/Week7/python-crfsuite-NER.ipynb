{
 "metadata": {
  "name": "",
  "signature": "sha256:8a6c198dbd3e949f0b21a24da9981898a30fcf63ce9b39def57d9f5a4c41758f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CRF\uae30\ubc18 \uac1c\ucc44\uba85 \uc778\uc2dd\uae30(Named Entitiy Recognizer) \ub9cc\ub4e4\uae30 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* CRFSuite \ucc38\uace0\ud560 \uac83 - http://www.chokkan.org/software/crfsuite/\n",
      "* \ucd9c\ucc98 - http://nbviewer.ipython.org/github/tpeng/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb\n",
      "* \uc0ac\uc6a9 \ud328\ud0a4\uc9c0 : \n",
      "    * python-crfsuite - http://python-crfsuite.readthedocs.org/en/latest/\n",
      "    * nltk\n",
      "    * scikit-learn"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Keywords"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Linear-chain (first-order Markov) CRF\n",
      "* Naemd Entities Recognition (NER)\n",
      "* Naemd Entities Recognition Using CRF"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Linear-chain (first-order Markov) CRF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(url='http://www.codeproject.com/KB/recipes/559535/gerative-discriminative.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://www.codeproject.com/KB/recipes/559535/gerative-discriminative.png\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "<IPython.core.display.Image at 0x38eb74d0>"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='http://zaxtax.github.io/scipy2013_struct/files/crf_chain.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://zaxtax.github.io/scipy2013_struct/files/crf_chain.png\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "<IPython.core.display.Image at 0x1c8c2150>"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naemd Entities Recognition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='http://wwatana.be/educational-facilita/images/educational_facilita_ner.jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://wwatana.be/educational-facilita/images/educational_facilita_ner.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "<IPython.core.display.Image at 0x38eb7190>"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naemd Entities Recognition Using CRF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='http://deliveryimages.acm.org/10.1145/1410000/1409378/figs/f3.jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"http://deliveryimages.acm.org/10.1145/1410000/1409378/figs/f3.jpg\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "<IPython.core.display.Image at 0x38eb7510>"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Leg's Go"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\ub2e4\uc74c\uc744 \uc124\uce58\ud558\uc790\n",
      "* python-crfsuite : CRFSuite\uc758 python wrapper \ud328\ud0a4\uc9c0. CRF \ubaa8\ub378\ub9c1\uc744 \uc704\ud574\uc11c \ud544\uc694\ud558\ub2e4.\n",
      "* nltk : \ud30c\uc774\uc36c \uc790\uc5f0\uc5b4\ucc98\ub9ac \ud328\ud0a4\uc9c0. \uc5ec\uae30\uc5d0 \uc608\uc81c \ub370\uc774\ud130(\ud559\uc2b5/\ud14c\uc2a4\ud2b8)\uac00 \ub4e4\uc5b4\uc788\ub2e4. Computational Natural Langauage Learning\uc774\ub77c\ub294 \ucee8\ud37c\ub7f0\uc2a4\uc758 2002\ub144 \ub370\uc774\ud130\ub97c \uc774\uc6a9\ud55c\ub2e4.\n",
      "* scikit-learn : \ud30c\uc774\uc36c \uae30\uacc4\ud559\uc2b5 \ud328\ud0a4\uc9c0. pycrfsuite\uc758 \ud559\uc2b5\uacb0\uacfc, \ubd84\ub958\uc131\ub2a5\uc744 \ubcf4\uae30 \uc704\ud574\uc11c.\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pip install python-crfsuite \n",
      "#pip install nltk\n",
      "#pip install scikit-learn\n",
      "from IPython.display import HTML\n",
      "\n",
      "from itertools import chain\n",
      "import nltk\n",
      "from sklearn.metrics import classification_report, confusion_matrix\n",
      "from sklearn.preprocessing import LabelBinarizer\n",
      "import sklearn\n",
      "import pycrfsuite\n",
      "\n",
      "print(sklearn.__version__)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.15.2\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Let's use CoNLL 2002 data to build a NER system\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = HTML('http://www.cnts.ua.ac.be/conll2002/')\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<html>\n",
        "<head>\n",
        "<title>Conference on Computational Natural Language Learning (CoNLL-2002)</title>\n",
        "</head>\n",
        "<body bgcolor=\"#ffffff\"><p>\n",
        "<table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" width=\"100%\">\n",
        "<tr><td bgcolor=\"#00ccff\" valign=\"top\">&nbsp;\n",
        "</table><p>\n",
        "\n",
        "<h1>Conference on Computational Natural Language Learning (CoNLL-2002)</h1>\n",
        "<p>\n",
        "The yearly meeting of the \n",
        "<a href=\"http://www.aclweb.org/signll/\">SIGNLL</a>, \n",
        "the Special Interest Group on Natural Language Learning of\n",
        "the Association for Computational Linguistics.\n",
        "The 2002 edition was held as a workshop at\n",
        "<a href=\"http://www.coling2002.sinica.edu.tw/\">Coling 2002</a>\n",
        "in Taipei, Taiwan and took place at August 31 and September 1, 2002.\n",
        "<p>\n",
        "<ul>\n",
        "<li> <a href=\"proceedings.html\">Proceedings</a>\n",
        "     with abstracts and papers\n",
        "<li> <a href=\"ner/\">Shared task description</a> \n",
        "     with results and papers\n",
        "<li> <a href=\"http://ilk.kub.nl/~signll/conll02/\">Old information</a>\n",
        "     (programme and submission schedule)\n",
        "</ul>\n",
        "<p>\n",
        "<h2>Links</h2>\n",
        "<p>\n",
        "<ul>\n",
        "<li> <a href=\"../conll2008/\">CoNLL-2008</a>\n",
        "<li> <a href=\"../conll2007/\">CoNLL-2007</a>\n",
        "<li> <a href=\"../conll2006/\">CoNLL-2006</a>\n",
        "     (New York City, USA),\n",
        "     <a href=\"http://nextens.uvt.nl/~conll/\">shared task</a>,\n",
        "     <a href=\"../conll2006/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll/\">CoNLL-2005</a>\n",
        "     (Ann Arbor, MI, USA), \n",
        "     <a href=\"http://www.lsi.upc.edu/~srlconll/st05/st05.html\">shared task</a>,\n",
        "     <a href=\"http://acl.ldc.upenn.edu/W/W05/#W05-0600\">proceedings</a>.\n",
        "<li> <a href=\"../conll2004/\">CoNLL-2004</a>\n",
        "     (Boston, MA, USA),\n",
        "     <a href=\"http://www.lsi.upc.edu/~srlconll/st04/st04.html\">shared task</a>,\n",
        "     <a href=\"../conll2004/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2003/\">CoNLL-2003</a>\n",
        "     (Edmonton, Canada),\n",
        "     <a href=\"../conll2003/ner/\">shared task</a>,\n",
        "     <a href=\"../conll2003/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2002/\">CoNLL-2002</a>\n",
        "     (Taipei, Taiwan),\n",
        "     <a href=\"../conll2002/ner/\">shared task</a>,\n",
        "     <a href=\"../conll2002/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2001/\">CoNLL-2001</a>\n",
        "     (Toulouse, France),\n",
        "     <a href=\"../conll2001/clauses/\">shared task</a>,\n",
        "     <a href=\"../conll2001/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2000/\">CoNLL-2000</a>\n",
        "     (Lisbon, Portugal),\n",
        "     <a href=\"../conll2000/chunking/\">shared task</a>,\n",
        "     <a href=\"../conll2000/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll99/\">CoNLL-99</a>\n",
        "     (Bergen, Norway),\n",
        "     <a href=\"../conll99/npb/\">shared task</a>,\n",
        "     <a href=\"../conll99/programme.html\">proceedings</a>.\n",
        "<li> <a href=\"http://www.cs.flinders.edu.au/research/AI/CoNLL/\">CoNLL-98</a>\n",
        "     (Sydney, Australia),\n",
        "     <a href=\"../conll98/proceedings.html\">proceedings</a>.\n",
        "<li> <a  href=\"http://www.cogsci.ed.ac.uk/~conll97/\">CoNLL-97</a>\n",
        "     (Madrid, Spain),\n",
        "     <a href=\"../conll97/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"http://ifarm.nl/signll/\">SIGNLL</a>:\n",
        "     ACL's Special Interest Group on Natural Language Learning\n",
        "</ul>\n",
        "<p>\n",
        "<hr>\n",
        "<address>\n",
        "Last update: September 30, 2011.\n",
        "erikt (at) xs4all.nl\n",
        "</address>\n",
        "</body>\n",
        "</html>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "<IPython.core.display.HTML at 0x38df1710>"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CoNLL2002 corpus is available in NLTK. We use Spanish data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.conll2002.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[u'esp.testa',\n",
        " u'esp.testb',\n",
        " u'esp.train',\n",
        " u'ned.testa',\n",
        " u'ned.testb',\n",
        " u'ned.train']"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
      "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 2.87 s, sys: 136 ms, total: 3.01 s\n",
        "Wall time: 3.04 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Data format:\n",
      "train_sents[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "[(u'Melbourne', u'NP', u'B-LOC'),\n",
        " (u'(', u'Fpa', u'O'),\n",
        " (u'Australia', u'NP', u'B-LOC'),\n",
        " (u')', u'Fpt', u'O'),\n",
        " (u',', u'Fc', u'O'),\n",
        " (u'25', u'Z', u'O'),\n",
        " (u'may', u'NC', u'O'),\n",
        " (u'(', u'Fpa', u'O'),\n",
        " (u'EFE', u'NC', u'B-ORG'),\n",
        " (u')', u'Fpt', u'O'),\n",
        " (u'.', u'Fp', u'O')]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Features"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def word2features(sent, i):\n",
      "    word = sent[i][0]\n",
      "    postag = sent[i][1]\n",
      "    features = [\n",
      "        'bias',\n",
      "        'word.lower=' + word.lower(),\n",
      "        'word[-3:]=' + word[-3:],\n",
      "        'word[-2:]=' + word[-2:],\n",
      "        'word.isupper=%s' % word.isupper(),\n",
      "        'word.istitle=%s' % word.istitle(),\n",
      "        'word.isdigit=%s' % word.isdigit(),\n",
      "        'postag=' + postag,\n",
      "        'postag[:2]=' + postag[:2],\n",
      "    ]\n",
      "    if i > 0:\n",
      "        word1 = sent[i-1][0]\n",
      "        postag1 = sent[i-1][1]\n",
      "        features.extend([\n",
      "            '-1:word.lower=' + word1.lower(),\n",
      "            '-1:word.istitle=%s' % word1.istitle(),\n",
      "            '-1:word.isupper=%s' % word1.isupper(),\n",
      "            '-1:postag=' + postag1,\n",
      "            '-1:postag[:2]=' + postag1[:2],\n",
      "        ])\n",
      "    else:\n",
      "        features.append('BOS')\n",
      "        \n",
      "    if i < len(sent)-1:\n",
      "        word1 = sent[i+1][0]\n",
      "        postag1 = sent[i+1][1]\n",
      "        features.extend([\n",
      "            '+1:word.lower=' + word1.lower(),\n",
      "            '+1:word.istitle=%s' % word1.istitle(),\n",
      "            '+1:word.isupper=%s' % word1.isupper(),\n",
      "            '+1:postag=' + postag1,\n",
      "            '+1:postag[:2]=' + postag1[:2],\n",
      "        ])\n",
      "    else:\n",
      "        features.append('EOS')\n",
      "                \n",
      "    return features\n",
      "\n",
      "\n",
      "def sent2features(sent):\n",
      "    return [word2features(sent, i) for i in range(len(sent))]\n",
      "\n",
      "def sent2labels(sent):\n",
      "    return [label for token, postag, label in sent]\n",
      "\n",
      "def sent2tokens(sent):\n",
      "    return [token for token, postag, label in sent] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This is what word2features extracts:\n",
      "sent2features(train_sents[0])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['bias',\n",
        " u'word.lower=melbourne',\n",
        " u'word[-3:]=rne',\n",
        " u'word[-2:]=ne',\n",
        " 'word.isupper=False',\n",
        " 'word.istitle=True',\n",
        " 'word.isdigit=False',\n",
        " u'postag=NP',\n",
        " u'postag[:2]=NP',\n",
        " 'BOS',\n",
        " u'+1:word.lower=(',\n",
        " '+1:word.istitle=False',\n",
        " '+1:word.isupper=False',\n",
        " u'+1:postag=Fpa',\n",
        " u'+1:postag[:2]=Fp']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Extract the features from the data:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X_train = [sent2features(s) for s in train_sents]\n",
      "y_train = [sent2labels(s) for s in train_sents]\n",
      "\n",
      "X_test = [sent2features(s) for s in test_sents]\n",
      "y_test = [sent2labels(s) for s in test_sents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3.43 s, sys: 260 ms, total: 3.69 s\n",
        "Wall time: 3.85 s\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(X_train), len(X_train)\n",
      "print type(X_train[0]), len(X_train[0])\n",
      "print type(X_train[1]), len(X_train[1])\n",
      "print type(X_train[2]), len(X_train[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'list'> 8323\n",
        "<type 'list'> 11\n",
        "<type 'list'> 1\n",
        "<type 'list'> 40\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "[['bias',\n",
        "  u'word.lower=melbourne',\n",
        "  u'word[-3:]=rne',\n",
        "  u'word[-2:]=ne',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=True',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NP',\n",
        "  u'postag[:2]=NP',\n",
        "  'BOS',\n",
        "  u'+1:word.lower=(',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpa',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=(',\n",
        "  u'word[-3:]=(',\n",
        "  u'word[-2:]=(',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpa',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=melbourne',\n",
        "  '-1:word.istitle=True',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=NP',\n",
        "  u'-1:postag[:2]=NP',\n",
        "  u'+1:word.lower=australia',\n",
        "  '+1:word.istitle=True',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=NP',\n",
        "  u'+1:postag[:2]=NP'],\n",
        " ['bias',\n",
        "  u'word.lower=australia',\n",
        "  u'word[-3:]=lia',\n",
        "  u'word[-2:]=ia',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=True',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NP',\n",
        "  u'postag[:2]=NP',\n",
        "  u'-1:word.lower=(',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpa',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  u'+1:word.lower=)',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpt',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=)',\n",
        "  u'word[-3:]=)',\n",
        "  u'word[-2:]=)',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpt',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=australia',\n",
        "  '-1:word.istitle=True',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=NP',\n",
        "  u'-1:postag[:2]=NP',\n",
        "  u'+1:word.lower=,',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fc',\n",
        "  u'+1:postag[:2]=Fc'],\n",
        " ['bias',\n",
        "  u'word.lower=,',\n",
        "  u'word[-3:]=,',\n",
        "  u'word[-2:]=,',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fc',\n",
        "  u'postag[:2]=Fc',\n",
        "  u'-1:word.lower=)',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpt',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  u'+1:word.lower=25',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Z',\n",
        "  u'+1:postag[:2]=Z'],\n",
        " ['bias',\n",
        "  u'word.lower=25',\n",
        "  u'word[-3:]=25',\n",
        "  u'word[-2:]=25',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=True',\n",
        "  u'postag=Z',\n",
        "  u'postag[:2]=Z',\n",
        "  u'-1:word.lower=,',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fc',\n",
        "  u'-1:postag[:2]=Fc',\n",
        "  u'+1:word.lower=may',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=NC',\n",
        "  u'+1:postag[:2]=NC'],\n",
        " ['bias',\n",
        "  u'word.lower=may',\n",
        "  u'word[-3:]=may',\n",
        "  u'word[-2:]=ay',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NC',\n",
        "  u'postag[:2]=NC',\n",
        "  u'-1:word.lower=25',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Z',\n",
        "  u'-1:postag[:2]=Z',\n",
        "  u'+1:word.lower=(',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpa',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=(',\n",
        "  u'word[-3:]=(',\n",
        "  u'word[-2:]=(',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpa',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=may',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=NC',\n",
        "  u'-1:postag[:2]=NC',\n",
        "  u'+1:word.lower=efe',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=True',\n",
        "  u'+1:postag=NC',\n",
        "  u'+1:postag[:2]=NC'],\n",
        " ['bias',\n",
        "  u'word.lower=efe',\n",
        "  u'word[-3:]=EFE',\n",
        "  u'word[-2:]=FE',\n",
        "  'word.isupper=True',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NC',\n",
        "  u'postag[:2]=NC',\n",
        "  u'-1:word.lower=(',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpa',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  u'+1:word.lower=)',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpt',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=)',\n",
        "  u'word[-3:]=)',\n",
        "  u'word[-2:]=)',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpt',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=efe',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=True',\n",
        "  u'-1:postag=NC',\n",
        "  u'-1:postag[:2]=NC',\n",
        "  u'+1:word.lower=.',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fp',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=.',\n",
        "  u'word[-3:]=.',\n",
        "  u'word[-2:]=.',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fp',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=)',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpt',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  'EOS']]"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "[['bias',\n",
        "  u'word.lower=-',\n",
        "  u'word[-3:]=-',\n",
        "  u'word[-2:]=-',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fg',\n",
        "  u'postag[:2]=Fg',\n",
        "  'BOS',\n",
        "  'EOS']]"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(y_train), len(y_train)\n",
      "print type(y_train[0]), len(y_train[0])\n",
      "print type(y_train[1]), len(y_train[1])\n",
      "print type(y_train[2]), len(y_train[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'list'> 8323\n",
        "<type 'list'> 11\n",
        "<type 'list'> 1\n",
        "<type 'list'> 40\n"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[u'B-LOC', u'O', u'B-LOC', u'O', u'O', u'O', u'O', u'O', u'B-ORG', u'O', u'O']"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "[u'O']"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train the model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "To train the model, we create pycrfsuite.Trainer, load the training data and call 'train' method. First, create pycrfsuite.Trainer and load the training data to CRFsuite:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trainer = pycrfsuite.Trainer(verbose=False)\n",
      "\n",
      "for xseq, yseq in zip(X_train, y_train):\n",
      "    trainer.append(xseq, yseq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.69 s, sys: 0 ns, total: 4.69 s\n",
        "Wall time: 4.68 s\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.set_params({\n",
      "    'c1': 1.0,   # coefficient for L1 penalty\n",
      "    'c2': 1e-3,  # coefficient for L2 penalty\n",
      "    'max_iterations': 50,  # stop earlier\n",
      "\n",
      "    # include transitions that are possible, but not observed\n",
      "    'feature.possible_transitions': True\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 107,
       "text": [
        "['feature.minfreq',\n",
        " 'feature.possible_states',\n",
        " 'feature.possible_transitions',\n",
        " 'c1',\n",
        " 'c2',\n",
        " 'max_iterations',\n",
        " 'num_memories',\n",
        " 'epsilon',\n",
        " 'period',\n",
        " 'delta',\n",
        " 'linesearch',\n",
        " 'max_linesearch']"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trainer.train('conll2002-esp.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3min 52s, sys: 304 ms, total: 3min 52s\n",
        "Wall time: 3min 52s\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Make predictions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "To use the trained model, create pycrfsuite.Tagger, open the model and use \"tag\" method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger = pycrfsuite.Tagger()\n",
      "tagger.open('conll2002-esp.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "<contextlib.closing at 0x8a88890>"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Let's tag a sentence to see how it works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_sent = test_sents[0]\n",
      "#print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
      "print(' '.join(sent2tokens(example_sent)) + '\\n')\n",
      "\n",
      "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
      "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "La Coru\u00f1a , 23 may ( EFECOM ) .\n",
        "\n",
        "('Predicted:', 'B-LOC I-LOC O O O O B-ORG O O')\n",
        "('Correct:  ', u'B-LOC I-LOC O O O O B-ORG O O')\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluate the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bio_classification_report(y_true, y_pred):\n",
      "    \"\"\"\n",
      "    Classification report for a list of BIO-encoded sequences.\n",
      "    It computes token-level metrics and discards \"O\" labels.\n",
      "    \n",
      "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
      "    to calculate averages properly!\n",
      "    \"\"\"\n",
      "    lb = LabelBinarizer()\n",
      "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
      "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
      "        \n",
      "    tagset = set(lb.classes_) - {'O'}\n",
      "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
      "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
      "    \n",
      "    return classification_report(\n",
      "        y_true_combined,\n",
      "        y_pred_combined,\n",
      "        labels = [class_indices[cls] for cls in tagset],\n",
      "        target_names = tagset,\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Predict entity labels for all sentences in our testing set ('testb' Spanish data):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "y_pred = [tagger.tag(xseq) for xseq in X_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 656 ms, sys: 4 ms, total: 660 ms\n",
        "Wall time: 658 ms\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bio_classification_report(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "      B-LOC       0.78      0.75      0.76      1084\n",
        "      I-LOC       0.87      0.93      0.90       634\n",
        "     B-MISC       0.69      0.47      0.56       339\n",
        "     I-MISC       0.87      0.93      0.90       634\n",
        "      B-ORG       0.82      0.87      0.84       735\n",
        "      I-ORG       0.61      0.49      0.54       557\n",
        "      B-PER       0.69      0.47      0.56       339\n",
        "      I-PER       0.87      0.93      0.90       634\n",
        "\n",
        "avg / total       0.79      0.77      0.78      4956\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Let's check what classifier learned"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "info = tagger.info()\n",
      "\n",
      "def print_transitions(trans_features):\n",
      "    for (label_from, label_to), weight in trans_features:\n",
      "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
      "\n",
      "print(\"Top likely transitions:\")\n",
      "print_transitions(Counter(info.transitions).most_common(15))\n",
      "\n",
      "print(\"\\nTop unlikely transitions:\")\n",
      "print_transitions(Counter(info.transitions).most_common()[-15:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top likely transitions:\n",
        "B-ORG  -> I-ORG   8.631963\n",
        "I-ORG  -> I-ORG   7.833706\n",
        "B-PER  -> I-PER   6.998706\n",
        "B-LOC  -> I-LOC   6.913675\n",
        "I-MISC -> I-MISC  6.129735\n",
        "B-MISC -> I-MISC  5.538291\n",
        "I-LOC  -> I-LOC   4.983567\n",
        "I-PER  -> I-PER   3.748358\n",
        "B-ORG  -> B-LOC   1.727090\n",
        "B-PER  -> B-LOC   1.388267\n",
        "B-LOC  -> B-LOC   1.240278\n",
        "O      -> O       1.197929\n",
        "O      -> B-ORG   1.097062\n",
        "I-PER  -> B-LOC   1.083332\n",
        "O      -> B-MISC  1.046113\n",
        "\n",
        "Top unlikely transitions:\n",
        "I-PER  -> B-ORG   -2.056130\n",
        "I-LOC  -> I-ORG   -2.143940\n",
        "B-ORG  -> I-MISC  -2.167501\n",
        "I-PER  -> I-ORG   -2.369380\n",
        "B-ORG  -> I-PER   -2.378110\n",
        "I-MISC -> I-PER   -2.458788\n",
        "B-LOC  -> I-PER   -2.516414\n",
        "I-ORG  -> I-MISC  -2.571973\n",
        "I-LOC  -> B-PER   -2.697791\n",
        "I-LOC  -> I-PER   -3.065950\n",
        "I-ORG  -> I-PER   -3.364434\n",
        "O      -> I-PER   -7.322841\n",
        "O      -> I-MISC  -7.648246\n",
        "O      -> I-ORG   -8.024126\n",
        "O      -> I-LOC   -8.333815\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized. Also note I-PER -> B-LOC transition: a positive weight means that model thinks that a person name is often followed by a location."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Check the state features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_state_features(state_features):\n",
      "    for (attr, label), weight in state_features:\n",
      "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
      "\n",
      "print(\"Top positive:\")\n",
      "print_state_features(Counter(info.state_features).most_common(20))\n",
      "\n",
      "print(\"\\nTop negative:\")\n",
      "print_state_features(Counter(info.state_features).most_common()[-20:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top positive:\n",
        "8.886516 B-ORG  word.lower=efe-cantabria\n",
        "8.743642 B-ORG  word.lower=psoe-progresistas\n",
        "5.769032 B-LOC  -1:word.lower=cantabria\n",
        "5.195429 I-LOC  -1:word.lower=calle\n",
        "5.116821 O      word.lower=mayo\n",
        "4.990871 O      -1:word.lower=d\u00eda\n",
        "4.910915 I-ORG  -1:word.lower=l\n",
        "4.721572 B-MISC word.lower=diversia\n",
        "4.676259 B-ORG  word.lower=telef\u00f3nica\n",
        "4.334354 B-ORG  word[-2:]=-e\n",
        "4.149862 B-ORG  word.lower=amena\n",
        "4.141370 B-ORG  word.lower=terra\n",
        "3.942852 O      word.istitle=False\n",
        "3.926397 B-ORG  word.lower=continente\n",
        "3.924672 B-ORG  word.lower=acesa\n",
        "3.888706 O      word.lower=euro\n",
        "3.856445 B-PER  -1:word.lower=seg\u00fan\n",
        "3.812373 B-MISC word.lower=exteriores\n",
        "3.807582 I-MISC -1:word.lower=1.9\n",
        "3.807098 B-MISC word.lower=sanidad\n",
        "\n",
        "Top negative:\n",
        "-1.965379 O      word.lower=fundaci\u00f3n\n",
        "-1.981541 O      -1:word.lower=brit\u00e1nica\n",
        "-2.118347 O      word.lower=061\n",
        "-2.190653 B-PER  word[-3:]=nes\n",
        "-2.226373 B-ORG  postag=SP\n",
        "-2.226373 B-ORG  postag[:2]=SP\n",
        "-2.260972 O      word[-3:]=uia\n",
        "-2.384920 O      -1:word.lower=secci\u00f3n\n",
        "-2.483009 O      word[-2:]=s.\n",
        "-2.535050 I-LOC  BOS\n",
        "-2.583123 O      -1:word.lower=s\u00e1nchez\n",
        "-2.585756 O      postag[:2]=NP\n",
        "-2.585756 O      postag=NP\n",
        "-2.588899 O      word[-2:]=om\n",
        "-2.738583 O      -1:word.lower=carretera\n",
        "-2.913103 O      word.istitle=True\n",
        "-2.926560 O      word[-2:]=nd\n",
        "-2.946862 I-PER  -1:word.lower=san\n",
        "-2.954094 B-PER  -1:word.lower=del\n",
        "-3.529449 O      word.isupper=True\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some observations:\n",
      "\n",
      " * 8.743642 B-ORG word.lower=psoe-progresistas - the model remembered names of some entities - maybe it is overfit, or maybe our features are not adequate, or maybe remembering is indeed helpful;\n",
      " * 5.195429 I-LOC -1:word.lower=calle: \"calle\" is a street in Spanish; model learns that if a previous word was \"calle\" then the token is likely a part of location;\n",
      " * -3.529449 O word.isupper=True, -2.913103 O word.istitle=True : UPPERCASED or TitleCased words are likely entities of some kind;\n",
      " * -2.585756 O postag=NP - proper nouns (NP is a proper noun in the Spanish tagset) are often entities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}