{
 "metadata": {
  "name": "",
  "signature": "sha256:93a0d18cf40b207cc7aebf66dc74e8bc2b18b7cb20fe814e734dc18f2c748888"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CRF\uae30\ubc18 \uac1c\ucc44\uba85 \uc778\uc2dd\uae30(Named Entitiy Recognizer) \ub9cc\ub4e4\uae30 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* \ucd9c\ucc98 - http://nbviewer.ipython.org/github/tpeng/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb\n",
      "* \uc0ac\uc6a9 \ud328\ud0a4\uc9c0 : \n",
      "    * python-crfsuite - http://python-crfsuite.readthedocs.org/en/latest/\n",
      "    * nltk\n",
      "    * scikit-learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pip install python-crfuite \n",
      "#pip install nltk\n",
      "#pip install scikit-learn\n",
      "from IPython.display import HTML\n",
      "\n",
      "from itertools import chain\n",
      "import nltk\n",
      "from sklearn.metrics import classification_report, confusion_matrix\n",
      "from sklearn.preprocessing import LabelBinarizer\n",
      "import sklearn\n",
      "import pycrfsuite\n",
      "\n",
      "print(sklearn.__version__)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.15.2\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Let's use CoNLL 2002 data to build a NER system\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = HTML('http://www.cnts.ua.ac.be/conll2002/')\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<html>\n",
        "<head>\n",
        "<title>Conference on Computational Natural Language Learning (CoNLL-2002)</title>\n",
        "</head>\n",
        "<body bgcolor=\"#ffffff\"><p>\n",
        "<table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" width=\"100%\">\n",
        "<tr><td bgcolor=\"#00ccff\" valign=\"top\">&nbsp;\n",
        "</table><p>\n",
        "\n",
        "<h1>Conference on Computational Natural Language Learning (CoNLL-2002)</h1>\n",
        "<p>\n",
        "The yearly meeting of the \n",
        "<a href=\"http://www.aclweb.org/signll/\">SIGNLL</a>, \n",
        "the Special Interest Group on Natural Language Learning of\n",
        "the Association for Computational Linguistics.\n",
        "The 2002 edition was held as a workshop at\n",
        "<a href=\"http://www.coling2002.sinica.edu.tw/\">Coling 2002</a>\n",
        "in Taipei, Taiwan and took place at August 31 and September 1, 2002.\n",
        "<p>\n",
        "<ul>\n",
        "<li> <a href=\"proceedings.html\">Proceedings</a>\n",
        "     with abstracts and papers\n",
        "<li> <a href=\"ner/\">Shared task description</a> \n",
        "     with results and papers\n",
        "<li> <a href=\"http://ilk.kub.nl/~signll/conll02/\">Old information</a>\n",
        "     (programme and submission schedule)\n",
        "</ul>\n",
        "<p>\n",
        "<h2>Links</h2>\n",
        "<p>\n",
        "<ul>\n",
        "<li> <a href=\"../conll2008/\">CoNLL-2008</a>\n",
        "<li> <a href=\"../conll2007/\">CoNLL-2007</a>\n",
        "<li> <a href=\"../conll2006/\">CoNLL-2006</a>\n",
        "     (New York City, USA),\n",
        "     <a href=\"http://nextens.uvt.nl/~conll/\">shared task</a>,\n",
        "     <a href=\"../conll2006/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll/\">CoNLL-2005</a>\n",
        "     (Ann Arbor, MI, USA), \n",
        "     <a href=\"http://www.lsi.upc.edu/~srlconll/st05/st05.html\">shared task</a>,\n",
        "     <a href=\"http://acl.ldc.upenn.edu/W/W05/#W05-0600\">proceedings</a>.\n",
        "<li> <a href=\"../conll2004/\">CoNLL-2004</a>\n",
        "     (Boston, MA, USA),\n",
        "     <a href=\"http://www.lsi.upc.edu/~srlconll/st04/st04.html\">shared task</a>,\n",
        "     <a href=\"../conll2004/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2003/\">CoNLL-2003</a>\n",
        "     (Edmonton, Canada),\n",
        "     <a href=\"../conll2003/ner/\">shared task</a>,\n",
        "     <a href=\"../conll2003/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2002/\">CoNLL-2002</a>\n",
        "     (Taipei, Taiwan),\n",
        "     <a href=\"../conll2002/ner/\">shared task</a>,\n",
        "     <a href=\"../conll2002/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2001/\">CoNLL-2001</a>\n",
        "     (Toulouse, France),\n",
        "     <a href=\"../conll2001/clauses/\">shared task</a>,\n",
        "     <a href=\"../conll2001/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll2000/\">CoNLL-2000</a>\n",
        "     (Lisbon, Portugal),\n",
        "     <a href=\"../conll2000/chunking/\">shared task</a>,\n",
        "     <a href=\"../conll2000/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"../conll99/\">CoNLL-99</a>\n",
        "     (Bergen, Norway),\n",
        "     <a href=\"../conll99/npb/\">shared task</a>,\n",
        "     <a href=\"../conll99/programme.html\">proceedings</a>.\n",
        "<li> <a href=\"http://www.cs.flinders.edu.au/research/AI/CoNLL/\">CoNLL-98</a>\n",
        "     (Sydney, Australia),\n",
        "     <a href=\"../conll98/proceedings.html\">proceedings</a>.\n",
        "<li> <a  href=\"http://www.cogsci.ed.ac.uk/~conll97/\">CoNLL-97</a>\n",
        "     (Madrid, Spain),\n",
        "     <a href=\"../conll97/proceedings.html\">proceedings</a>.\n",
        "<li> <a href=\"http://ifarm.nl/signll/\">SIGNLL</a>:\n",
        "     ACL's Special Interest Group on Natural Language Learning\n",
        "</ul>\n",
        "<p>\n",
        "<hr>\n",
        "<address>\n",
        "Last update: September 30, 2011.\n",
        "erikt (at) xs4all.nl\n",
        "</address>\n",
        "</body>\n",
        "</html>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "<IPython.core.display.HTML at 0x38df1710>"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = HTML('http://www.cnts.ua.ac.be/conll2002/ner/')\n",
      "h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<html><head><title>\n",
        "Language-Independent Named Entity Recognition (I)\n",
        "</title></head><body bgcolor=\"#ffffff\"><p>\n",
        "<table cellpadding=\"0\" cellspacing=\"0\" border=\"0\" width=\"100%\">\n",
        "<tr><td bgcolor=\"#00ccff\" valign=\"top\">&nbsp;\n",
        "</table><p>\n",
        "\n",
        "<h1>Language-Independent Named Entity Recognition (I)</h1>\n",
        "<p>\n",
        "Named entities are phrases that contain the names of persons,\n",
        "organizations, locations, times and quantities.\n",
        "Example:\n",
        "<p>\n",
        "<blockquote>\n",
        "[PER <font color=\"#ff0000\">Wolff</font> ] \n",
        ",  currently a journalist in \n",
        "[LOC <font color=\"#00ff00\">Argentina</font> ] \n",
        ", played with\n",
        "[PER <font color=\"#ff0000\">Del Bosque</font> ] \n",
        "in the final years of the seventies in\n",
        "[ORG <font color=\"#0000ff\">Real Madrid</font> ] \n",
        ".\n",
        "</blockquote>\n",
        "<p>\n",
        "The shared task of \n",
        "<a href=\"../\">CoNLL-2002</a>\n",
        "concerns language-independent named entity recognition.\n",
        "We will concentrate on four types of named entities: persons,\n",
        "locations, organizations and names of miscellaneous entities that do\n",
        "not belong to the previous three groups.\n",
        "The participants of the shared task will be offered training and test\n",
        "data for at least two languages.\n",
        "They will use the data for developing a named-entity recognition\n",
        "system that includes a machine learning component.\n",
        "Information sources other than the training data may be used in this\n",
        "shared task.\n",
        "We are especially interested in methods that can use additional\n",
        "unannotated data for improving their performance (for example\n",
        "co-training).\n",
        "<p>\n",
        "<h2>Background information</h2>\n",
        "<p>\n",
        "Named Entity Recognition (NER) is a subtask of Information Extraction.\n",
        "Different NER systems were evaluated as a part of the Sixth Message\n",
        "Understanding Conference in 1995\n",
        "(<a href=\"http://www.cs.nyu.edu/cs/faculty/grishman/muc6.html\">MUC6</a>).\n",
        "The target language was English.\n",
        "The participating systems performed well.\n",
        "However, many of them used language-specific resources for performing\n",
        "the task and it is unknown how they would have performed on another\n",
        "language than English [<a href=\"#PD97\">PD97</a>].\n",
        "<p>\n",
        "After 1995 NER systems have been developed for some European languages\n",
        "and a few Asian languages.\n",
        "There have been at least two studies that have applied one NER system\n",
        "to different languages.\n",
        "Palmer and Day [<a href=\"#PD97\">PD97</a>] have used statistical methods\n",
        "for finding named entities in newswire articles in Chinese, English,\n",
        "French, Japanese, Portuguese and Spanish.\n",
        "They found that the difficulty of the NER task was different for the\n",
        "six languages but that a large part of the task could be performed\n",
        "with simple methods.\n",
        "Cucerzan and Yarowsky [<a href=\"#CY99\">CY99</a>] used both\n",
        "morphological and contextual clues for identifying named entities in\n",
        "English, Greek, Hindi, Rumanian and Turkish.\n",
        "With minimal supervision, they obtained overall F measures between 40\n",
        "and 70, depending on the languages used.\n",
        "<p>\n",
        "<h2>Software and Data</h2>\n",
        "<p>\n",
        "The data consists of two columns separated by a single space.\n",
        "Each word has been put on a separate line and there is an empty line\n",
        "after each sentence.\n",
        "The first item on each line is a word and the second the named entity\n",
        "tag.\n",
        "The tags have the same format as in the chunking task: a B denotes the\n",
        "first item of a phrase and an I any non-initial word.\n",
        "There are four types of phrases: person names (PER), organizations\n",
        "(ORG), locations (LOC) and miscellaneous names (MISC).\n",
        "Here is an example:\n",
        "<p>\n",
        "<pre>\n",
        "        Wolff B-PER\n",
        "            , O\n",
        "    currently O\n",
        "            a O\n",
        "   journalist O\n",
        "           in O\n",
        "    Argentina B-LOC\n",
        "            , O\n",
        "       played O\n",
        "         with O\n",
        "          Del B-PER\n",
        "       Bosque I-PER\n",
        "           in O\n",
        "          the O\n",
        "        final O\n",
        "        years O\n",
        "           of O\n",
        "          the O\n",
        "    seventies O\n",
        "           in O\n",
        "         Real B-ORG\n",
        "       Madrid I-ORG\n",
        "            . O\n",
        "</pre>\n",
        "<p>\n",
        "The data consists of three files per language: one training file and\n",
        "two test files testa and testb.\n",
        "The first test file will be used in the development phase for finding\n",
        "good parameters for the learning system.\n",
        "The second test file will be used for the final evaluation.\n",
        "Currently there are data files available for two languages: Spanish\n",
        "and Dutch.\n",
        "<p>\n",
        "<ul>\n",
        "<li> <a href=\"http://www.cnts.ua.ac.be/conll2002/ner.tgz\">http://www.cnts.ua.ac.be/conll2002/ner.tgz</a>\n",
        "<br> The data sets and evaluation software for this shared task\n",
        "     in one gzipped tar file.\n",
        "     You can also retrieve these files one by one:\n",
        "     <a href=\"data/\">data</a> and\n",
        "     <a href=\"bin/\">software</a>.\n",
        "<br> Xavier Carreras provides the Spanish data sets with\n",
        "     <a href=\"http://www.lsi.upc.es/~nlp/tools/nerc/nerc.html\">part\n",
        "     of speech tags</a> (20030803)\n",
        "<li> <a href=\"http://www.cnts.ua.ac.be/conll2000/chunking/output.html\">http://www.cnts.ua.ac.be/conll2000/chunking/output.html</a>\n",
        "<br> Output example of the evaluation script for this shared task:\n",
        "     <a href=\"bin/conlleval.txt\">conlleval</a>.\n",
        "     The example deals with text chunking, a task which uses the same\n",
        "     output format as this named entity task.\n",
        "     The output of the NER system for each word should be appended\n",
        "     behind each line, with a single space between the line and the\n",
        "     output tag.\n",
        "</ul>\n",
        "<p>\n",
        "The Spanish data is a collection of news wire articles made\n",
        "available by the Spanish EFE News Agency. \n",
        "The articles are from May 2000. \n",
        "The annotation was carried out by the\n",
        "<a href=\"http://www.talp.upc.es/\">TALP Research Center</a>\n",
        "of the Technical University of Catalonia (UPC) and the\n",
        "<a href=\"http://clic.fil.ub.es/\">Center of Language and Computation (CLiC)</a>\n",
        "of the University of Barcelona (UB), and funded by the European Commission \n",
        "through the NAMIC project (IST-1999-12392).\n",
        "<p>\n",
        "The Dutch data consist of four editions of the Belgian newspaper\n",
        "\"De Morgen\" of 2000 (June 2, July 1, August 1 and September 1).\n",
        "The data was annotated as a part of the \n",
        "<a href=\"http://atranos.esat.kuleuven.ac.be/\">Atranos</a>\n",
        "project at the University of Antwerp.\n",
        "<p>\n",
        "If your have data for other languages that you would like to make\n",
        "available, please contact\n",
        "<a href=\"mailto:erikt@uia.ua.ac.be\">erikt@uia.ua.ac.be</a>\n",
        "We are interested in tokenized text files containing about 250,000\n",
        "words for which the named entities (names of persons, organizations,\n",
        "locations and other) have been marked up.\n",
        "<p>\n",
        "<h2>Results</h2>\n",
        "<p>\n",
        "Twelve systems have participated in the CoNLL-2002 shared task.\n",
        "They used a wide variety of machine learning techniques.\n",
        "Here is an overview of their performance on the two test data sets:\n",
        "<p>\n",
        "<pre>\n",
        "              +-----------+-----------++-----------++\n",
        "     Spanish  | precision |   recall  ||     F     ||\n",
        "   +----------+-----------+-----------++-----------++\n",
        "   | [<a href=\"#CMP02\">CMP02</a>]  |   81.38%  |   81.40%  ||   81.39   || &plusmn;1.5\n",
        "   | [<a href=\"#Flo02\">Flo02</a>]  |   78.70%  |   79.40%  ||   79.05   || &plusmn;1.4\n",
        "   | [<a href=\"#CY02\">CY02</a>]   |   78.19%  |   76.14%  ||   77.15   || &plusmn;1.4\n",
        "   | [<a href=\"#WNC02\">WNC02</a>]  |   75.85%  |   77.38%  ||   76.61   || &plusmn;1.4\n",
        "   | [<a href=\"#BHM02\">BHM02</a>]  |   74.19%  |   77.44%  ||   75.78   || &plusmn;1.4\n",
        "   | [<a href=\"#Tjo02\">Tjo02</a>]  |   76.00%  |   75.55%  ||   75.78   || &plusmn;1.5\n",
        "   | [<a href=\"#PWM02\">PWM02</a>]  |   74.32%  |   73.52%  ||   73.92   || &plusmn;1.5\n",
        "   | [<a href=\"#Jan02\">Jan02</a>]  |   74.03%  |   73.76%  ||   73.89   || &plusmn;1.5\n",
        "   | [<a href=\"#Mal02\">Mal02</a>]  |   73.93%  |   73.39%  ||   73.66   || &plusmn;1.6\n",
        "   | [<a href=\"#Tsu02\">Tsu02</a>]  |   69.04%  |   74.12%  ||   71.49   || &plusmn;1.4\n",
        "   | [<a href=\"#BV02\">BV02</a>]   |   60.53%  |   67.29%  ||   63.73   || &plusmn;1.8\n",
        "   | [<a href=\"#MM02\">MM02</a>]   |   56.28%  |   66.51%  ||   60.97   || &plusmn;1.7\n",
        "   +----------+-----------+-----------++-----------++\n",
        "   | baseline |   26.27%  |   56.48%  ||   35.86   || &plusmn;1.3\n",
        "   +----------+-----------+-----------++-----------++\n",
        "\n",
        "              +-----------+-----------++-----------++\n",
        "     Dutch    | precision |   recall  ||     F     ||\n",
        "   +----------+-----------+-----------++-----------++\n",
        "   | [<a href=\"#CMP02\">CMP02</a>]  |   77.83%  |   76.29%  ||   77.05   || &plusmn;1.5\n",
        "   | [<a href=\"#WNC02\">WNC02</a>]  |   76.95%  |   73.83%  ||   75.36   || &plusmn;1.6\n",
        "   | [<a href=\"#Flo02\">Flo02</a>]  |   75.10%  |   74.89%  ||   74.99   || &plusmn;1.5\n",
        "   | [<a href=\"#BHM02\">BHM02</a>]  |   72.69%  |   72.45%  ||   72.57   || &plusmn;1.4\n",
        "   | [<a href=\"#CY02\">CY02</a>]   |   73.03%  |   71.62%  ||   72.31   || &plusmn;1.6\n",
        "   | [<a href=\"#PWM02\">PWM02</a>]  |   74.01%  |   68.90%  ||   71.36   || &plusmn;1.6\n",
        "   | [<a href=\"#Tjo02\">Tjo02</a>]  |   72.56%  |   68.88%  ||   70.67   || &plusmn;1.6\n",
        "   | [<a href=\"#Jan02\">Jan02</a>]  |   70.11%  |   69.26%  ||   69.68   || &plusmn;1.7\n",
        "   | [<a href=\"#Mal02\">Mal02</a>]  |   70.88%  |   65.50%  ||   68.08   || &plusmn;1.9\n",
        "   | [<a href=\"#Tsu02\">Tsu02</a>]  |   57.33%  |   65.02%  ||   60.93   || &plusmn;1.7\n",
        "   | [<a href=\"#MM02\">MM02</a>]   |   56.22%  |   63.24%  ||   59.52   || &plusmn;2.0\n",
        "   | [<a href=\"#BV02\">BV02</a>]   |   51.89%  |   47.78%  ||   49.75   || &plusmn;2.2\n",
        "   +----------+-----------+-----------++-----------++\n",
        "   | baseline |   81.29%  |   45.42%  ||   58.28   || &plusmn;1.4\n",
        "   +----------+-----------+-----------++-----------++\n",
        "</pre>\n",
        "<p>\n",
        "Here are some remarks on these results:\n",
        "<p>\n",
        "<ul>\n",
        "<li>\n",
        "   The baseline results have been produced by a system which only\n",
        "   selects complete named entities which appear in the training data.\n",
        "<li>\n",
        "   The column to the right of the F rates shows estimations of the\n",
        "   significance intervals for the F rates.\n",
        "   They have been obtained with bootstrap resampling \n",
        "   [<a href=\"#Nor89\">Nor89</a>].\n",
        "   F rates outside of these intervals are assumed to be significantly\n",
        "   different from the related F rate (p&lt;0.05).\n",
        "<li>\n",
        "   The results of [<a href=\"#BV02\">BV02</a>] mentioned here are \n",
        "   different from those listed in the related paper because the \n",
        "   latter were produced by incorrect software.\n",
        "<li>\n",
        "   The baseline numbers for Dutch mentioned in the introduction paper \n",
        "   to this shared task have been generated from data sets with \n",
        "   errors and are thus different from those mentioned in the table here.\n",
        "<li>\n",
        "   The system of [<a href=\"#BV02\">BV02</a>] performs worse than the\n",
        "   baseline system when processing the Dutch data because the authors\n",
        "   used a poor representation of the data. \n",
        "   They had removed all sentence breaks.\n",
        "</ul>\n",
        "<p> \n",
        "The system of Xavier Carreras, Lu&iacute;s M&agrave;rquez and\n",
        "Lu&iacute;s Padr&oacute; [<a href=\"#CMP02\">CMP02</a>]\n",
        "outperformed all other systems by a significant margin, both on the\n",
        "Spanish test data (81.39) and the Dutch test data (77.05).\n",
        "It should be noted that they have used some additional information\n",
        "beside the training data in the Spanish experiment.\n",
        "Without this additional information their system (79.28) does not\n",
        "perform significantly better than that of [<a href=\"#Flo02\">Flo02</a>]\n",
        "(79.05). \n",
        "The [<a href=\"#CMP02\">CMP02</a>] system uses AdaBoost applied to\n",
        "decision trees. \n",
        "<p>\n",
        "The papers associated with the participating systems can be found in\n",
        "the reference section below. \n",
        "<p>\n",
        "<h2>Related information</h2>\n",
        "<p>\n",
        "<ul>\n",
        "<li> <a href=\"../../conll2003/ner/\">http://cnts.uia.ac.be/conll2003/ner/</a>\n",
        "<br> The CoNLL-2003 shared task deals with Language-Independent Named \n",
        "     Entity Recognition as well.\n",
        "<li> <a href=\"../\">http://cnts.uia.ac.be/conll2002/</a>\n",
        "<br> Home page of the workshop on Computational Natural Language\n",
        "     Learning (CoNLL-2002) of which this shared task is part of.\n",
        "<li> <a href=\"http://www.cs.nyu.edu/cs/faculty/grishman/muc6.html\">http://www.cs.nyu.edu/cs/faculty/grishman/muc6.html</a>\n",
        "<br> Home page of the Sixth Message Understanding Conference (1995)\n",
        "     that introduced named entity recognition as shared task.\n",
        "<li> <a href=\"http://www.itl.nist.gov/iaui/894.02/related_projects/muc/\">http://www.itl.nist.gov/iaui/894.02/related_projects/muc/</a>\n",
        "<br> Home page of the Seventh Message Understanding Conference (1998)\n",
        "     which contained a named entity recognition as shared task.\n",
        "<li> <a href=\"http://www.nist.gov/speech/tests/ie-er/er_99/er_99.htm\">http://www.nist.gov/speech/tests/ie-er/er_99/er_99.htm</a>\n",
        "<br> Home page of the 1999 DARPA-TIDES Information Extraction-Entity \n",
        "     Recognition (IE-ER) technology evaluation project, which contained\n",
        "     a named entity recognition task.\n",
        "<li> <a href=\"http://www.itl.nist.gov/iaui/894.02/related_projects/tipster/met.htm\">http://www.itl.nist.gov/iaui/894.02/related_projects/tipster/met.htm</a>\n",
        "<br> Information on the Multilingual Entity Task Conference (MET)\n",
        "     which contained named entity recognition for Chinese, Japanese\n",
        "     and Spanish\n",
        "     (<a href=\"http://www.itl.nist.gov/iaui/894.02/related_projects/muc/proceedings/muc_7_proceedings/overview.html\">overview</a>).\n",
        "<li> <a href=\"http://www.calle.com/world/\">http://www.calle.com/world/</a>\n",
        "<br> List of about 2.8 million locations on Earth.\n",
        "</ul>\n",
        "<p>\n",
        "<h2>References</h2>\n",
        "<p>\n",
        "This is a list of papers that are relevant for this task.\n",
        "<p>\n",
        "<h3>CoNLL-2002 Shared Task Papers</h3>\n",
        "<p>\n",
        "Note: in some cases the output files provided here contain results which\n",
        "are slightly different from those mentioned in the papers.\n",
        "<p>\n",
        "<ul>\n",
        "<li> <strong>[<a name=\"TKS02\">TKS02</a>]</strong><br>\n",
        "     Erik F. Tjong Kim Sang,\n",
        "     Introduction to the CoNLL-2002 Shared Task: Language-Independent\n",
        "     Named Entity Recognition.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 155-158. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/15558tjo.ps\">ps</a>]\n",
        "     [<a href=\"../ps/15558tjo.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/15558tjo.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/15558tjo.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     sheets:\n",
        "     [<a href=\"../ps/15558tjo.sh.ps\">ps</a>]\n",
        "     [<a href=\"../ps/15558tjo.sh.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/15558tjo.sh.pdf\">pdf</a>]\n",
        "<li> <strong>[<a name=\"BV02\">BV02</a>]</strong><br>\n",
        "     William J. Black and Argyrios Vasilakopoulos,\n",
        "     Language-Independent Named Entity Classification by\n",
        "     Modified Transformation-Based Learning and by\n",
        "     Decision Tree Induction.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 159-162. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/15962bla.ps\">ps</a>]\n",
        "     [<a href=\"../ps/15962bla.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/15962bla.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/15962bla.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/black.tgz\">tgz</a>]\n",
        "     [<a href=\"results/black/\">files</a>]\n",
        "<li> <strong>[<a name=\"BHM02\">BHM02</a>]</strong><br>\n",
        "     John D. Burger, John C. Henderson and William T. Morgan,\n",
        "     Statistical Named Entity Recognizer Adaptation.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 163-166. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/16366bur.ps\">ps</a>]\n",
        "     [<a href=\"../ps/16366bur.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/16366bur.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/16366bur.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/burger.tgz\">tgz</a>]\n",
        "     [<a href=\"results/burger/\">files</a>]\n",
        "<li> <strong>[<a name=\"CMP02\">CMP02</a>]</strong><br>\n",
        "     Xavier Carreras, Llu&iacute;s M&aacute;rques and Llu&iacute;s\n",
        "     Padr&oacute;, \n",
        "     Named Entity Extraction using AdaBoost\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 167-170. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/16770car.ps\">ps</a>]\n",
        "     [<a href=\"../ps/16770car.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/16770car.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/16770car.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/carreras.tgz\">tgz</a>]\n",
        "     [<a href=\"results/carreras/\">files</a>]\n",
        "<li> <strong>[<a name=\"CY02\">CY02</a>]</strong><br>\n",
        "     Silviu Cucerzan and David Yarowsky,\n",
        "     Language Independent NER using a Unified Model of \n",
        "     Internal and Contextual Evidence.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 171-174. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/17174cuc.ps\">ps</a>]\n",
        "     [<a href=\"../ps/17174cuc.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/17174cuc.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/17174cuc.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/cucerzan.tgz\">tgz</a>]\n",
        "     [<a href=\"results/cucerzan/\">files</a>]\n",
        "<li> <strong>[<a name=\"Flo02\">Flo02</a>]</strong><br>\n",
        "     Radu Florian,\n",
        "     Named Entity Recognition as a House of Cards: Classifier Stacking.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 175-178. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/17578flo.ps\">ps</a>]\n",
        "     [<a href=\"../ps/17578flo.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/17578flo.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/17578flo.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/florian.tgz\">tgz</a>]\n",
        "     [<a href=\"results/florian/\">files</a>]\n",
        "<li> <strong>[<a name=\"Jan02\">Jan02</a>]</strong><br>\n",
        "     Martin Jansche,\n",
        "     Named Entity Extraction with Conditional Markov\n",
        "     Models and Classifiers.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 179-182. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/17982jan.ps\">ps</a>]\n",
        "     [<a href=\"../ps/17982jan.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/17982jan.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/17982jan.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/jansche.tgz\">tgz</a>]\n",
        "     [<a href=\"results/jansche/\">files</a>]\n",
        "<li> <strong>[<a name=\"Mal02\">Mal02</a>]</strong><br>\n",
        "     Robert Malouf,\n",
        "     Markov models for language-independent named entity recognition.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 187-190. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/18790mal.ps\">ps</a>]\n",
        "     [<a href=\"../ps/18790mal.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/18790mal.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/18790mal.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/malouf.tgz\">tgz</a>]\n",
        "     [<a href=\"results/malouf/\">files</a>]\n",
        "<li> <strong>[<a name=\"MM02\">MM02</a>]</strong><br>\n",
        "     Paul McNamee and James Mayfield,\n",
        "     Entity Extraction Without Language-Specific Resources.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 183-186. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/18386mcn.ps\">ps</a>]\n",
        "     [<a href=\"../ps/18386mcn.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/18386mcn.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/18386mcn.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/mcnamee.tgz\">tgz</a>]\n",
        "     [<a href=\"results/mcnamee/\">files</a>]\n",
        "<li> <strong>[<a name=\"PWM02\">PWM02</a>]</strong><br>\n",
        "     Jon Patrick, Casey Whitelaw and Robert Munro,\n",
        "     SLINERC: The Sydney Language-Independent Named Entity \n",
        "     Recogniser and Classifier.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 199-202. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/19902pat.ps\">ps</a>]\n",
        "     [<a href=\"../ps/19902pat.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/19902pat.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/19902pat.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/patrick.tgz\">tgz</a>]\n",
        "     [<a href=\"results/patrick/\">files</a>]\n",
        "<li> <strong>[<a name=\"Tjo02\">Tjo02</a>]</strong><br>\n",
        "     Erik F. Tjong Kim Sang,\n",
        "     Memory-Based Named Entity Recognition.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 203-206. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/20306tjo.ps\">ps</a>]\n",
        "     [<a href=\"../ps/20306tjo.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/20306tjo.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/20306tjo.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/tjong.tgz\">tgz</a>]\n",
        "     [<a href=\"results/tjong/\">files</a>]\n",
        "<li> <strong>[<a name=\"Tsu02\">Tsu02</a>]</strong><br>\n",
        "     Koji Tsukamoto, Yutaka Mitsuishi and Manabu Sassano,\n",
        "     Learning with Multiple Stacking for Named Entity Recognition.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 191-194. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/19194tsu.ps\">ps</a>]\n",
        "     [<a href=\"../ps/19194tsu.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/19194tsu.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/19194tsu.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/tsukamoto.tgz\">tgz</a>]\n",
        "     [<a href=\"results/tsukamoto/\">files</a>]\n",
        "<li> <strong>[<a name=\"WNC02\">WNC02</a>]</strong><br>\n",
        "     Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen and Yongsheng Yang,\n",
        "     Boosting for Named Entity Recognition.\n",
        "     In: \n",
        "     <cite>Proceedings of CoNLL-2002</cite>,\n",
        "     Taipei, Taiwan, 2002, pp. 195-198. \n",
        "     <br>\n",
        "     paper:\n",
        "     [<a href=\"../ps/19598wu.ps\">ps</a>]\n",
        "     [<a href=\"../ps/19598wu.ps.gz\">ps.gz</a>]\n",
        "     [<a href=\"../pdf/19598wu.pdf\">pdf</a>]\n",
        "     [<a href=\"../bibtex/19598wu.txt\">bibtex</a>]\n",
        "     <br>\n",
        "     system output:\n",
        "     [<a href=\"results/wu.tgz\">tgz</a>]\n",
        "     [<a href=\"results/wu/\">files</a>]\n",
        "</ul>\n",
        "<p>\n",
        "<h3>Other related publications</h3>\n",
        "<p>\n",
        "A paper that is related to the topic of this shared task is\n",
        "the EMNLP-99 paper by \n",
        "Cucerzan and Yarowsky [<a href=\"#CY99\">CY99</a>].\n",
        "Interesting papers about using unsupervised data, though not for the\n",
        "NER task, are those of \n",
        "Mitchell [<a href=\"#Mit99\">Mit99</a>]\n",
        "and\n",
        "Banko and Brill [<a href=\"#BB01\">BB01</a>].\n",
        "<p>\n",
        "<ul>\n",
        "<li> <strong>[<a name=\"BB01\">BB01</a>]</strong><br>\n",
        "     Michele Banko and Eric Brill,\n",
        "     Scaling to Very Very Large Corpora for Natural Language\n",
        "     Disambiguation.\n",
        "     In <cite>Proceedings of ACL 2001</cite>,\n",
        "     Toulouse, France, 2001, pp. 26-33.\n",
        "<br> <a href=\"http://www.research.microsoft.com/users/mbanko/ACL2001VeryVeryLargeCorpora.pdf\">http://www.research.microsoft.com/users/mbanko/ACL2001VeryVeryLargeCorpora.pdf</a>\n",
        "<li> <strong>[<a name=\"Bor99\">Bor99</a>]</strong><br>\n",
        "     Andrew Borthwick,\n",
        "     <cite>A Maximum Entropy Approach to Named Entity\n",
        "     Recognition</cite>.\n",
        "     PhD thesis, New York University, 1999.\n",
        "<br> <a href=\"http://cs.nyu.edu/cs/projects/proteus/publication/papers/borthwick_thesis.ps\">http://cs.nyu.edu/cs/projects/proteus/publication/papers/borthwick_thesis.ps</a>\n",
        "<li> <strong>[<a name=\"BV00\">BV00</a>]</strong><br>\n",
        "     Sabine Buchholz and Antal van den Bosch,\n",
        "     Integrating seed names and n-grams for a named entity list and\n",
        "     classifier,\n",
        "     In: <cite>Proceedings of LREC-2000</cite>, Athens, Greece, June\n",
        "     2000, pp. 1215-1221. \n",
        "<br> <a href=\"http://ilk.kub.nl/downloads/pub/papers/ilk.0002.ps.gz\">http://ilk.kub.nl/downloads/pub/papers/ilk.0002.ps.gz</a>\n",
        "<li> <strong>[<a name=\"CBFR99\">CBFR99</a>]</strong><br>\n",
        "     Nancy Chinchor, Erica Brown, Lisa Ferro and Patty Robinson,\n",
        "     <cite>1999 Named Entity Recognition Task Definition</cite>,\n",
        "     MITRE, 1999.\n",
        "<br> <a href=\"http://www.nist.gov/speech/tests/ie-er/er_99/doc/ne99_taskdef_v1_4.pdf\">http://www.nist.gov/speech/tests/ie-er/er_99/doc/ne99_taskdef_v1_4.pdf</a>\n",
        "<li> <strong>[<a name=\"CBFR99\">CS99</a>]</strong><br>\n",
        "     Michael Collins and Yoram Singer,\n",
        "     Unsupervised models for named entity classification. \n",
        "     In <cite>Proceedings of the 1999 Joint SIGDAT Conference on Empirical\n",
        "     Methods in Natural Language Processing and Very Large\n",
        "     Corpora</cite>,\n",
        "     University of Maryland, MD, 1999.\n",
        "<br> <a href=\"http://citeseer.nj.nec.com/collins99unsupervised.html\">http://citeseer.nj.nec.com/collins99unsupervised.html</a>\n",
        "<li> <strong>[<a name=\"CY99\">CY99</a>]</strong><br>\n",
        "     Silviu Cucerzan and David Yarowsky, \n",
        "     Language independent named entity recognition combining\n",
        "     morphological and contextual evidence. \n",
        "     In <cite>Proceedings of 1999 Joint SIGDAT Conference on EMNLP and\n",
        "     VLC</cite>,\n",
        "     University of Maryland, MD, 1999.\n",
        "<br> <a href=\"http://citeseer.nj.nec.com/cucerzan99language.html\">http://citeseer.nj.nec.com/cucerzan99language.html</a>\n",
        "<li> <strong>[<a name=\"Mit99\">Mit99</a>]</strong><br>\n",
        "     Tom M. Mitchell,\n",
        "     The Role of Unlabeled Data in Supervised Learning.\n",
        "     In <cite>Proceedings of the Sixth International Colloquium on\n",
        "     Cognitive Science</cite>, \n",
        "     San Sebastian, Spain, 1999.\n",
        "<br> <a href=\"http://citeseer.nj.nec.com/mitchell99role.html\">http://citeseer.nj.nec.com/mitchell99role.html</a>\n",
        "<li> <strong>[<a name=\"MMG99\">MMG99</a>]</strong><br>\n",
        "     Andrei Mikheev, Marc Moens and Claire Grover,\n",
        "     Named Entity Recognition without Gazetteers,\n",
        "     In <cite>Proceedings of EACL'99</cite>,\n",
        "     Bergen, Norway, 1999, pp. 1-8.\n",
        "<br> <a href=\"http://www.ltg.ed.ac.uk/~mikheev/papers_my/eacl99.ps\">http://www.ltg.ed.ac.uk/~mikheev/papers_my/eacl99.ps</a>\n",
        "<li> <strong>[<a name=\"Nor89\">Nor89</a>]</strong><br>\n",
        "     Eric W. Noreen,\n",
        "     <cite>Computer-Intensive Methods for Testing Hypotheses</cite>\n",
        "     John Wiley & Sons,\n",
        "     1989.\n",
        "<li> <strong>[<a name=\"PD97\">PD97</a>]</strong><br>\n",
        "     David D. Palmer and David S. Day,\n",
        "     A Statistical Profile of the Named Entity Task.\n",
        "     In <cite>Proceedings of Fifth ACL Conference for Applied Natural\n",
        "     Language Processing (ANLP-97),</cite>\n",
        "     Washington D.C., 1997\n",
        "<br> <a href=\"http://crow.ee.washington.edu/people/palmer/papers/anlp97.ps\">http://crow.ee.washington.edu/people/palmer/papers/anlp97.ps</a>\n",
        "</ul>\n",
        "\n",
        "<p><hr><address>\n",
        "Last update: May 08, 2005.\n",
        "<a href=\"mailto:erikt@uia.ua.ac.be\">erikt@uia.ua.ac.be</a></address>\n",
        "<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>\n",
        "<br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br>\n",
        "<br>\n",
        "</body></html>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 99,
       "text": [
        "<IPython.core.display.HTML at 0x38ed8fd0>"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CoNLL2002 corpus is available in NLTK. We use Spanish data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.conll2002.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[u'esp.testa',\n",
        " u'esp.testb',\n",
        " u'esp.train',\n",
        " u'ned.testa',\n",
        " u'ned.testb',\n",
        " u'ned.train']"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
      "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 2.87 s, sys: 136 ms, total: 3.01 s\n",
        "Wall time: 3.04 s\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Data format:\n",
      "train_sents[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "[(u'Melbourne', u'NP', u'B-LOC'),\n",
        " (u'(', u'Fpa', u'O'),\n",
        " (u'Australia', u'NP', u'B-LOC'),\n",
        " (u')', u'Fpt', u'O'),\n",
        " (u',', u'Fc', u'O'),\n",
        " (u'25', u'Z', u'O'),\n",
        " (u'may', u'NC', u'O'),\n",
        " (u'(', u'Fpa', u'O'),\n",
        " (u'EFE', u'NC', u'B-ORG'),\n",
        " (u')', u'Fpt', u'O'),\n",
        " (u'.', u'Fp', u'O')]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Features"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def word2features(sent, i):\n",
      "    word = sent[i][0]\n",
      "    postag = sent[i][1]\n",
      "    features = [\n",
      "        'bias',\n",
      "        'word.lower=' + word.lower(),\n",
      "        'word[-3:]=' + word[-3:],\n",
      "        'word[-2:]=' + word[-2:],\n",
      "        'word.isupper=%s' % word.isupper(),\n",
      "        'word.istitle=%s' % word.istitle(),\n",
      "        'word.isdigit=%s' % word.isdigit(),\n",
      "        'postag=' + postag,\n",
      "        'postag[:2]=' + postag[:2],\n",
      "    ]\n",
      "    if i > 0:\n",
      "        word1 = sent[i-1][0]\n",
      "        postag1 = sent[i-1][1]\n",
      "        features.extend([\n",
      "            '-1:word.lower=' + word1.lower(),\n",
      "            '-1:word.istitle=%s' % word1.istitle(),\n",
      "            '-1:word.isupper=%s' % word1.isupper(),\n",
      "            '-1:postag=' + postag1,\n",
      "            '-1:postag[:2]=' + postag1[:2],\n",
      "        ])\n",
      "    else:\n",
      "        features.append('BOS')\n",
      "        \n",
      "    if i < len(sent)-1:\n",
      "        word1 = sent[i+1][0]\n",
      "        postag1 = sent[i+1][1]\n",
      "        features.extend([\n",
      "            '+1:word.lower=' + word1.lower(),\n",
      "            '+1:word.istitle=%s' % word1.istitle(),\n",
      "            '+1:word.isupper=%s' % word1.isupper(),\n",
      "            '+1:postag=' + postag1,\n",
      "            '+1:postag[:2]=' + postag1[:2],\n",
      "        ])\n",
      "    else:\n",
      "        features.append('EOS')\n",
      "                \n",
      "    return features\n",
      "\n",
      "\n",
      "def sent2features(sent):\n",
      "    return [word2features(sent, i) for i in range(len(sent))]\n",
      "\n",
      "def sent2labels(sent):\n",
      "    return [label for token, postag, label in sent]\n",
      "\n",
      "def sent2tokens(sent):\n",
      "    return [token for token, postag, label in sent] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This is what word2features extracts:\n",
      "sent2features(train_sents[0])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['bias',\n",
        " u'word.lower=melbourne',\n",
        " u'word[-3:]=rne',\n",
        " u'word[-2:]=ne',\n",
        " 'word.isupper=False',\n",
        " 'word.istitle=True',\n",
        " 'word.isdigit=False',\n",
        " u'postag=NP',\n",
        " u'postag[:2]=NP',\n",
        " 'BOS',\n",
        " u'+1:word.lower=(',\n",
        " '+1:word.istitle=False',\n",
        " '+1:word.isupper=False',\n",
        " u'+1:postag=Fpa',\n",
        " u'+1:postag[:2]=Fp']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Extract the features from the data:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "X_train = [sent2features(s) for s in train_sents]\n",
      "y_train = [sent2labels(s) for s in train_sents]\n",
      "\n",
      "X_test = [sent2features(s) for s in test_sents]\n",
      "y_test = [sent2labels(s) for s in test_sents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 3.43 s, sys: 260 ms, total: 3.69 s\n",
        "Wall time: 3.85 s\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "[['bias',\n",
        "  u'word.lower=melbourne',\n",
        "  u'word[-3:]=rne',\n",
        "  u'word[-2:]=ne',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=True',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NP',\n",
        "  u'postag[:2]=NP',\n",
        "  'BOS',\n",
        "  u'+1:word.lower=(',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpa',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=(',\n",
        "  u'word[-3:]=(',\n",
        "  u'word[-2:]=(',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpa',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=melbourne',\n",
        "  '-1:word.istitle=True',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=NP',\n",
        "  u'-1:postag[:2]=NP',\n",
        "  u'+1:word.lower=australia',\n",
        "  '+1:word.istitle=True',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=NP',\n",
        "  u'+1:postag[:2]=NP'],\n",
        " ['bias',\n",
        "  u'word.lower=australia',\n",
        "  u'word[-3:]=lia',\n",
        "  u'word[-2:]=ia',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=True',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NP',\n",
        "  u'postag[:2]=NP',\n",
        "  u'-1:word.lower=(',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpa',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  u'+1:word.lower=)',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpt',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=)',\n",
        "  u'word[-3:]=)',\n",
        "  u'word[-2:]=)',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpt',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=australia',\n",
        "  '-1:word.istitle=True',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=NP',\n",
        "  u'-1:postag[:2]=NP',\n",
        "  u'+1:word.lower=,',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fc',\n",
        "  u'+1:postag[:2]=Fc'],\n",
        " ['bias',\n",
        "  u'word.lower=,',\n",
        "  u'word[-3:]=,',\n",
        "  u'word[-2:]=,',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fc',\n",
        "  u'postag[:2]=Fc',\n",
        "  u'-1:word.lower=)',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpt',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  u'+1:word.lower=25',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Z',\n",
        "  u'+1:postag[:2]=Z'],\n",
        " ['bias',\n",
        "  u'word.lower=25',\n",
        "  u'word[-3:]=25',\n",
        "  u'word[-2:]=25',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=True',\n",
        "  u'postag=Z',\n",
        "  u'postag[:2]=Z',\n",
        "  u'-1:word.lower=,',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fc',\n",
        "  u'-1:postag[:2]=Fc',\n",
        "  u'+1:word.lower=may',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=NC',\n",
        "  u'+1:postag[:2]=NC'],\n",
        " ['bias',\n",
        "  u'word.lower=may',\n",
        "  u'word[-3:]=may',\n",
        "  u'word[-2:]=ay',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NC',\n",
        "  u'postag[:2]=NC',\n",
        "  u'-1:word.lower=25',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Z',\n",
        "  u'-1:postag[:2]=Z',\n",
        "  u'+1:word.lower=(',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpa',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=(',\n",
        "  u'word[-3:]=(',\n",
        "  u'word[-2:]=(',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpa',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=may',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=NC',\n",
        "  u'-1:postag[:2]=NC',\n",
        "  u'+1:word.lower=efe',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=True',\n",
        "  u'+1:postag=NC',\n",
        "  u'+1:postag[:2]=NC'],\n",
        " ['bias',\n",
        "  u'word.lower=efe',\n",
        "  u'word[-3:]=EFE',\n",
        "  u'word[-2:]=FE',\n",
        "  'word.isupper=True',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=NC',\n",
        "  u'postag[:2]=NC',\n",
        "  u'-1:word.lower=(',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpa',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  u'+1:word.lower=)',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fpt',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=)',\n",
        "  u'word[-3:]=)',\n",
        "  u'word[-2:]=)',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fpt',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=efe',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=True',\n",
        "  u'-1:postag=NC',\n",
        "  u'-1:postag[:2]=NC',\n",
        "  u'+1:word.lower=.',\n",
        "  '+1:word.istitle=False',\n",
        "  '+1:word.isupper=False',\n",
        "  u'+1:postag=Fp',\n",
        "  u'+1:postag[:2]=Fp'],\n",
        " ['bias',\n",
        "  u'word.lower=.',\n",
        "  u'word[-3:]=.',\n",
        "  u'word[-2:]=.',\n",
        "  'word.isupper=False',\n",
        "  'word.istitle=False',\n",
        "  'word.isdigit=False',\n",
        "  u'postag=Fp',\n",
        "  u'postag[:2]=Fp',\n",
        "  u'-1:word.lower=)',\n",
        "  '-1:word.istitle=False',\n",
        "  '-1:word.isupper=False',\n",
        "  u'-1:postag=Fpt',\n",
        "  u'-1:postag[:2]=Fp',\n",
        "  'EOS']]"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_train[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[u'B-LOC', u'O', u'B-LOC', u'O', u'O', u'O', u'O', u'O', u'B-ORG', u'O', u'O']"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train the model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "To train the model, we create pycrfsuite.Trainer, load the training data and call 'train' method. First, create pycrfsuite.Trainer and load the training data to CRFsuite:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trainer = pycrfsuite.Trainer(verbose=False)\n",
      "\n",
      "for xseq, yseq in zip(X_train, y_train):\n",
      "    trainer.append(xseq, yseq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 4.22 s, sys: 0 ns, total: 4.22 s\n",
        "Wall time: 4.27 s\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.set_params({\n",
      "    'c1': 1.0,   # coefficient for L1 penalty\n",
      "    'c2': 1e-3,  # coefficient for L2 penalty\n",
      "    'max_iterations': 50,  # stop earlier\n",
      "\n",
      "    # include transitions that are possible, but not observed\n",
      "    'feature.possible_transitions': True\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "['feature.minfreq',\n",
        " 'feature.possible_states',\n",
        " 'feature.possible_transitions',\n",
        " 'c1',\n",
        " 'c2',\n",
        " 'max_iterations',\n",
        " 'num_memories',\n",
        " 'epsilon',\n",
        " 'period',\n",
        " 'delta',\n",
        " 'linesearch',\n",
        " 'max_linesearch']"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trainer.train('conll2002-esp.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 26.2 s, sys: 20 ms, total: 26.2 s\n",
        "Wall time: 26.2 s\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Make predictions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "To use the trained model, create pycrfsuite.Tagger, open the model and use \"tag\" method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger = pycrfsuite.Tagger()\n",
      "tagger.open('conll2002-esp.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "<contextlib.closing at 0x8a88890>"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Let's tag a sentence to see how it works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_sent = test_sents[0]\n",
      "#print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
      "print(' '.join(sent2tokens(example_sent)) + '\\n')\n",
      "\n",
      "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
      "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "La Coru\u00f1a , 23 may ( EFECOM ) .\n",
        "\n",
        "('Predicted:', 'B-LOC I-LOC O O O O B-ORG O O')\n",
        "('Correct:  ', u'B-LOC I-LOC O O O O B-ORG O O')\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluate the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bio_classification_report(y_true, y_pred):\n",
      "    \"\"\"\n",
      "    Classification report for a list of BIO-encoded sequences.\n",
      "    It computes token-level metrics and discards \"O\" labels.\n",
      "    \n",
      "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
      "    to calculate averages properly!\n",
      "    \"\"\"\n",
      "    lb = LabelBinarizer()\n",
      "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
      "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
      "        \n",
      "    tagset = set(lb.classes_) - {'O'}\n",
      "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
      "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
      "    \n",
      "    return classification_report(\n",
      "        y_true_combined,\n",
      "        y_pred_combined,\n",
      "        labels = [class_indices[cls] for cls in tagset],\n",
      "        target_names = tagset,\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Predict entity labels for all sentences in our testing set ('testb' Spanish data):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "y_pred = [tagger.tag(xseq) for xseq in X_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 656 ms, sys: 4 ms, total: 660 ms\n",
        "Wall time: 658 ms\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(bio_classification_report(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "      B-LOC       0.78      0.75      0.76      1084\n",
        "      I-LOC       0.87      0.93      0.90       634\n",
        "     B-MISC       0.69      0.47      0.56       339\n",
        "     I-MISC       0.87      0.93      0.90       634\n",
        "      B-ORG       0.82      0.87      0.84       735\n",
        "      I-ORG       0.61      0.49      0.54       557\n",
        "      B-PER       0.69      0.47      0.56       339\n",
        "      I-PER       0.87      0.93      0.90       634\n",
        "\n",
        "avg / total       0.79      0.77      0.78      4956\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Let's check what classifier learned"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "info = tagger.info()\n",
      "\n",
      "def print_transitions(trans_features):\n",
      "    for (label_from, label_to), weight in trans_features:\n",
      "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
      "\n",
      "print(\"Top likely transitions:\")\n",
      "print_transitions(Counter(info.transitions).most_common(15))\n",
      "\n",
      "print(\"\\nTop unlikely transitions:\")\n",
      "print_transitions(Counter(info.transitions).most_common()[-15:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top likely transitions:\n",
        "B-ORG  -> I-ORG   8.631963\n",
        "I-ORG  -> I-ORG   7.833706\n",
        "B-PER  -> I-PER   6.998706\n",
        "B-LOC  -> I-LOC   6.913675\n",
        "I-MISC -> I-MISC  6.129735\n",
        "B-MISC -> I-MISC  5.538291\n",
        "I-LOC  -> I-LOC   4.983567\n",
        "I-PER  -> I-PER   3.748358\n",
        "B-ORG  -> B-LOC   1.727090\n",
        "B-PER  -> B-LOC   1.388267\n",
        "B-LOC  -> B-LOC   1.240278\n",
        "O      -> O       1.197929\n",
        "O      -> B-ORG   1.097062\n",
        "I-PER  -> B-LOC   1.083332\n",
        "O      -> B-MISC  1.046113\n",
        "\n",
        "Top unlikely transitions:\n",
        "I-PER  -> B-ORG   -2.056130\n",
        "I-LOC  -> I-ORG   -2.143940\n",
        "B-ORG  -> I-MISC  -2.167501\n",
        "I-PER  -> I-ORG   -2.369380\n",
        "B-ORG  -> I-PER   -2.378110\n",
        "I-MISC -> I-PER   -2.458788\n",
        "B-LOC  -> I-PER   -2.516414\n",
        "I-ORG  -> I-MISC  -2.571973\n",
        "I-LOC  -> B-PER   -2.697791\n",
        "I-LOC  -> I-PER   -3.065950\n",
        "I-ORG  -> I-PER   -3.364434\n",
        "O      -> I-PER   -7.322841\n",
        "O      -> I-MISC  -7.648246\n",
        "O      -> I-ORG   -8.024126\n",
        "O      -> I-LOC   -8.333815\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized. Also note I-PER -> B-LOC transition: a positive weight means that model thinks that a person name is often followed by a location."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Check the state features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_state_features(state_features):\n",
      "    for (attr, label), weight in state_features:\n",
      "        print(\"%0.6f %-6s %s\" % (weight, label, attr))    \n",
      "\n",
      "print(\"Top positive:\")\n",
      "print_state_features(Counter(info.state_features).most_common(20))\n",
      "\n",
      "print(\"\\nTop negative:\")\n",
      "print_state_features(Counter(info.state_features).most_common()[-20:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top positive:\n",
        "8.886516 B-ORG  word.lower=efe-cantabria\n",
        "8.743642 B-ORG  word.lower=psoe-progresistas\n",
        "5.769032 B-LOC  -1:word.lower=cantabria\n",
        "5.195429 I-LOC  -1:word.lower=calle\n",
        "5.116821 O      word.lower=mayo\n",
        "4.990871 O      -1:word.lower=d\u00eda\n",
        "4.910915 I-ORG  -1:word.lower=l\n",
        "4.721572 B-MISC word.lower=diversia\n",
        "4.676259 B-ORG  word.lower=telef\u00f3nica\n",
        "4.334354 B-ORG  word[-2:]=-e\n",
        "4.149862 B-ORG  word.lower=amena\n",
        "4.141370 B-ORG  word.lower=terra\n",
        "3.942852 O      word.istitle=False\n",
        "3.926397 B-ORG  word.lower=continente\n",
        "3.924672 B-ORG  word.lower=acesa\n",
        "3.888706 O      word.lower=euro\n",
        "3.856445 B-PER  -1:word.lower=seg\u00fan\n",
        "3.812373 B-MISC word.lower=exteriores\n",
        "3.807582 I-MISC -1:word.lower=1.9\n",
        "3.807098 B-MISC word.lower=sanidad\n",
        "\n",
        "Top negative:\n",
        "-1.965379 O      word.lower=fundaci\u00f3n\n",
        "-1.981541 O      -1:word.lower=brit\u00e1nica\n",
        "-2.118347 O      word.lower=061\n",
        "-2.190653 B-PER  word[-3:]=nes\n",
        "-2.226373 B-ORG  postag=SP\n",
        "-2.226373 B-ORG  postag[:2]=SP\n",
        "-2.260972 O      word[-3:]=uia\n",
        "-2.384920 O      -1:word.lower=secci\u00f3n\n",
        "-2.483009 O      word[-2:]=s.\n",
        "-2.535050 I-LOC  BOS\n",
        "-2.583123 O      -1:word.lower=s\u00e1nchez\n",
        "-2.585756 O      postag[:2]=NP\n",
        "-2.585756 O      postag=NP\n",
        "-2.588899 O      word[-2:]=om\n",
        "-2.738583 O      -1:word.lower=carretera\n",
        "-2.913103 O      word.istitle=True\n",
        "-2.926560 O      word[-2:]=nd\n",
        "-2.946862 I-PER  -1:word.lower=san\n",
        "-2.954094 B-PER  -1:word.lower=del\n",
        "-3.529449 O      word.isupper=True\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some observations:\n",
      "\n",
      " * 8.743642 B-ORG word.lower=psoe-progresistas - the model remembered names of some entities - maybe it is overfit, or maybe our features are not adequate, or maybe remembering is indeed helpful;\n",
      " * 5.195429 I-LOC -1:word.lower=calle: \"calle\" is a street in Spanish; model learns that if a previous word was \"calle\" then the token is likely a part of location;\n",
      " * -3.529449 O word.isupper=True, -2.913103 O word.istitle=True : UPPERCASED or TitleCased words are likely entities of some kind;\n",
      " * -2.585756 O postag=NP - proper nouns (NP is a proper noun in the Spanish tagset) are often entities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}